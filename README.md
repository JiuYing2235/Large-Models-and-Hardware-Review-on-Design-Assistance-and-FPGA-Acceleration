# Paper on FPGA-based LLM accelerator
This list focuses on understanding optimization methods for FPGA-based Large Language Model (LLM) accelerators.   
     
Paper recommendations (accepted by conference or journal): Please contact me.  

## Papers
### 2025  
* [Design and Implementation of an FPGA-Based Hardware Accelerator for Transformer](http://arxiv.org/abs/2503.16731)
  * [Sparsification], [Tiling Strategy], [Memory Access Optimization]
* [FÂ³: An FPGA-based Transformer Fine-tuning Accelerator with Flexible Floating Point Format](https://ieeexplore.ieee.org/document/10945317/)
  * [Quantization], [Reconfigurable PE Array]
* [FPGA Acceleration With Hessian-Based Comprehensive Intra-Layer Mixed-Precision Quantization for Transformer Models](https://ieeexplore.ieee.org/document/10973048/)
  * [Sparsification], [Quantization]
* [InTAR: Inter-Task Auto-Reconfigurable Accelerator Design for High Data Volume Variation in DNNs](http://arxiv.org/abs/2502.08807)
  * [Reconfigurable PE Array], [Memory Access Optimization], [Kernel Fusion]
### 2024
* [Understanding the Potential of FPGA-Based Spatial Acceleration for Large Language Model Inference](http://arxiv.org/abs/2312.15159)
  * [Quantization], [Systolic Array], [Memory Access Optimization]
* [FAMOUS: Flexible Accelerator for the Attention Mechanism of Transformer on UltraScale+ FPGAs](http://arxiv.org/abs/2409.14023)
  * [Tiling Strategy]
* [A Runtime-Adaptive Transformer Neural Network Accelerator on FPGAs](http://arxiv.org/abs/2411.18148)
  * [Tiling Strategy]
* [An FPGA-Based Transformer Accelerator With Parallel Unstructured Sparsity Handling for Question-Answering Applications](https://ieeexplore.ieee.org/document/10681589/)
  * [Sparsification], [Memory Access Optimization]
* [Energy Efficient FPGA-Based Accelerator for Dynamic Sparse Transformer](https://ieeexplore.ieee.org/document/10652850/)
  * [Sparsification]
* [Energy Efficient FPGA-Based Binary Transformer Accelerator for Edge Devices](https://ieeexplore.ieee.org/document/10558631/)
  * [Quantization], [Approximate Computing Units]
* []()
  * [], [], []
* []()
  * [], [], []
* []()
  * [], [], []
* []()
  * [], [], []
* []()
  * [], [], []
