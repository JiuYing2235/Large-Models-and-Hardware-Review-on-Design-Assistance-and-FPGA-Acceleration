# Large Model-Assisted Hardware Design
* VRank: Enhancing Verilog Code Generation from Large Language Models via Self-Consistency. [10.48550/arXiv.2502.00028](http://arxiv.org/abs/2502.00028)
* VerilogReader: LLM-Aided Hardware Test Generation. [10.1109/LAD62341.2024.10691801](http://arxiv.org/abs/2406.04373)
* VerilogEval: Evaluating Large Language Models for Verilog Code Generation. [10.48550/arXiv.2309.07544](http://arxiv.org/abs/2309.07544)
* VeriGen: A Large Language Model for Verilog Code Generation. [10.1145/3643681](https://dl.acm.org/doi/10.1145/3643681)
* UVLLM: An Automated Universal RTL Verification Framework using LLMs. [10.48550/arXiv.2411.16238](http://arxiv.org/abs/2411.16238)
* Towards LLM-Powered Verilog RTL Assistant: Self-Verification and Self-Correction. [10.48550/arXiv.2406.00115](http://arxiv.org/abs/2406.00115)
* PyHDL-Eval: An LLM Evaluation Framework for Hardware Design Using Python-Embedded DSLs. [10.1145/3670474.3685948](https://dl.acm.org/doi/10.1145/3670474.3685948)
* Paradigm-Based Automatic HDL Code Generation Using LLMs. [10.48550/arXiv.2501.12702](http://arxiv.org/abs/2501.12702)
* OriGen:Enhancing RTL Code Generation with Code-to-Code Augmentation and Self-Reflection. [10.48550/arXiv.2407.16237](http://arxiv.org/abs/2407.16237)
* OPL4GPT: An Application Space Exploration of Optimal Programming Language for Hardware Design by LLM. [10.1145/3658617.3697621](https://dl.acm.org/doi/10.1145/3658617.3697621)
* MAGE: A Multi-Agent Engine for Automated RTL Code Generation. [10.48550/arXiv.2412.07822](http://arxiv.org/abs/2412.07822)
* LLM for Complex Signal Processing in FPGA-based Software Defined Radios: A Case Study on FFT. [10.1109/VTC2024-Fall63153.2024.10757597](https://ieeexplore.ieee.org/document/10757597/)
* LintLLM: An Open-Source Verilog Linting Framework Based on Large Language Models. [10.48550/arXiv.2502.10815](http://arxiv.org/abs/2502.10815)
* HiVeGen -- Hierarchical LLM-based Verilog Generation for Scalable Chip Design. [10.48550/arXiv.2412.05393](http://arxiv.org/abs/2412.05393)
* HaVen: Hallucination-Mitigated LLM for Verilog Code Generation Aligned with HDL Engineers. [10.48550/arXiv.2501.04908](http://arxiv.org/abs/2501.04908)
* Exploring Large Language Models for Verilog Hardware Design Generation. [10.1109/IPDPSW63119.2024.00034](https://ieeexplore.ieee.org/document/10596478/)
* Data is all you need: Finetuning LLMs for Chip Design via an Automated design-data augmentation framework. [10.1145/3649329.3657356](https://dl.acm.org/doi/10.1145/3649329.3657356)
* CodeV: Empowering LLMs for Verilog Generation through Multi-Level Summarization. [10.48550/arXiv.2407.10424](http://arxiv.org/abs/2407.10424)
* ChipGPT: How far are we from natural language hardware design. [10.48550/arXiv.2305.14019](http://arxiv.org/abs/2305.14019)
* Benchmarking Large Language Models for Automated Verilog RTL Code Generation. [10.23919/DATE56975.2023.10137086](https://ieeexplore.ieee.org/document/10137086/)
* AutoVCoder: A Systematic Framework for Automated Verilog Code Generation using LLMs. [10.48550/arXiv.2407.18333](http://arxiv.org/abs/2407.18333)
* AutoChip: Automating HDL Generation Using LLM Feedback. [10.48550/arXiv.2311.04887](http://arxiv.org/abs/2311.04887)
* Are LLMs Any Good for High-Level Synthesis?. [10.48550/arXiv.2408.10428](http://arxiv.org/abs/2408.10428)
* Advanced Large Language Model (LLM)-Driven Verilog Development: Enhancing Power, Performance, and Area Optimization in Code Synthesis. [10.48550/arXiv.2312.01022](http://arxiv.org/abs/2312.01022)
* A Multi-Expert Large Language Model Architecture for Verilog Code Generation. [10.1109/LAD62341.2024.10691683](http://arxiv.org/abs/2404.08029)
* SynthAI: A Multi Agent Generative AI Framework for Automated Modular HLS Design Generation. [10.48550/arXiv.2405.16072](http://arxiv.org/abs/2405.16072)
* HLSPilot: LLM-based High-Level Synthesis. [10.48550/arXiv.2408.06810](http://arxiv.org/abs/2408.06810)
* GPT4AIGChip: Towards Next-Generation AI Accelerator Design Automation via Large Language Models. [10.48550/arXiv.2309.10730](http://arxiv.org/abs/2309.10730)
* Exploring Code Language Models for Automated HLS-based Hardware Generation: Benchmark, Infrastructure and Analysis. [10.1145/3658617.3697616](https://dl.acm.org/doi/10.1145/3658617.3697616)
* Evaluating Large Language Models for Automatic Register Transfer Logic Generation via High-Level Synthesis. [10.48550/arXiv.2408.02793](http://arxiv.org/abs/2408.02793)
* C2HLSC: Leveraging Large Language Models to Bridge the Software-to-Hardware Design Gap. [10.1145/3734524](https://doi.org/10.1145/3734524)
* Automated C/C++ Program Repair for High-Level Synthesis via Large Language Models. [10.1145/3670474.3685953](https://dl.acm.org/doi/10.1145/3670474.3685953)
* LLM-aided explanations of EDA synthesis errors. [10.1109/LAD62341.2024.10691721](https://ieeexplore.ieee.org/document/10691721/)
* LLM-Aided Efficient Hardware Design Automation. [10.48550/arXiv.2410.18582](http://arxiv.org/abs/2410.18582)
* HDLdebugger: Streamlining HDL debugging with Large Language Models. [10.48550/arXiv.2403.11671](http://arxiv.org/abs/2403.11671)
* Classification-Based Automatic HDL Code Generation Using LLMs. [10.48550/arXiv.2407.18326](http://arxiv.org/abs/2407.18326)
* A new design approach of hardware implementation through natural language entry. [10.1049/cim2.12087](https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cim2.12087)
* SpecLLM: Exploring Generation and Review of VLSI Design Specification with Large Language Model. [10.48550/arXiv.2401.13266](http://arxiv.org/abs/2401.13266)
* Research on the Application of Large Language Models in FPGA Verification Test Requirement Extraction. [10.1109/ICDSCA63855.2024.10859460](https://ieeexplore.ieee.org/document/10859460/)
* Combining LLM Code Generation with Formal Specifications and Reactive Program Synthesis. [10.48550/arXiv.2410.19736](http://arxiv.org/abs/2410.19736)
# FPGA-Based LLM Accelerators
* TerEffic: Highly Efficient Ternary LLM Inference on FPGA. [10.48550/arXiv.2502.16473](http://arxiv.org/abs/2502.16473)
* TeLLMe: An Energy-Efficient Ternary LLM Accelerator for Prefilling and Decoding on Edge FPGAs. [10.48550/arXiv.2504.16266](http://arxiv.org/abs/2504.16266)
* Pushing up to the Limit of Memory Bandwidth and Capacity Utilization for Efficient LLM Decoding on Embedded FPGA. [10.48550/arXiv.2502.10659](http://arxiv.org/abs/2502.10659)
* On-Device Qwen2.5: Efficient LLM Inference with Model Compression and Hardware Acceleration. [10.48550/arXiv.2504.17376](http://arxiv.org/abs/2504.17376)
* LoopLynx: A Scalable Dataflow Architecture for Efficient LLM Inference. [10.48550/arXiv.2504.09561](http://arxiv.org/abs/2504.09561)
* LlamaF: An Efficient Llama2 Architecture Accelerator on Embedded FPGAs. [10.48550/arXiv.2409.11424](http://arxiv.org/abs/2409.11424)
* LightMamba: Efficient Mamba Acceleration on FPGA with Quantization and Hardware Co-design. [10.48550/arXiv.2502.15260](http://arxiv.org/abs/2502.15260)
* Hummingbird: A Smaller and Faster Large Language Model Accelerator on Embedded FPGA. [10.48550/arXiv.2507.03308](http://arxiv.org/abs/2507.03308)
* GLITCHES: GPU-FPGA LLM Inference Through a Collaborative Heterogeneous System. [10.1109/HPEC62836.2024.10938498](https://ieeexplore.ieee.org/abstract/document/10938498)
* FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs. [10.48550/arXiv.2401.03868](http://arxiv.org/abs/2401.03868)
* EdgeLLM: A Highly Efficient CPU-FPGA Heterogeneous Edge Accelerator for Large Language Models. [10.1109/TCSI.2025.3546256](https://ieeexplore.ieee.org/abstract/document/10916480)
* DFX: A Low-latency Multi-FPGA Appliance for Accelerating Transformer-based Text Generation. [10.48550/arXiv.2209.10797](http://arxiv.org/abs/2209.10797)
* Designing Efficient LLM Accelerators for Edge Devices. [10.48550/arXiv.2408.00462](http://arxiv.org/abs/2408.00462)
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
* . []()
  
